{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bff0ff",
   "metadata": {},
   "source": [
    "#### 1. Import packages\n",
    "**Note**: Rememeber to always import functions from *functions.py* file\n",
    "\n",
    "##### If the packages from the *requirements.txt* are **absent**, they can be installed via **!pip** command. \n",
    "##### One needs to do it only once. Example of installation is given below. The lines are commented with # symbol. \n",
    "##### Run the cell where the packages are imported. If an error of type *'no module named... is found'* occurs:\n",
    "1.  delete # before the corresponding package name \n",
    "2.  run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffe1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install requests\n",
    "# !pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0cae9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b3810",
   "metadata": {},
   "source": [
    "### Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e062a7f5-e345-4fa8-9784-6d907f21d0b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T09:41:06.977907Z",
     "iopub.status.busy": "2021-12-14T09:41:06.977289Z",
     "iopub.status.idle": "2021-12-14T09:41:07.001649Z",
     "shell.execute_reply": "2021-12-14T09:41:07.001020Z",
     "shell.execute_reply.started": "2021-12-14T09:41:06.977858Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sonata_amphora_data_for_ABM.csv', sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae69a23d-a543-4e9f-bf07-9d2857707cfd",
   "metadata": {},
   "source": [
    "### Adding site information\n",
    "In order to create map plots coordinates are needed. From the provided pleiades urls for each site, the longitude and lattidude can be scraped. This is done in the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7bae67",
   "metadata": {},
   "source": [
    "To begin with the dataframes with a pleaides url for each site are read. The coordinates of sites that does not have a pleaides url are also provided in this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b28230d6-84a7-4386-9640-286187fa3244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:39:53.943034Z",
     "iopub.status.busy": "2021-12-07T14:39:53.942602Z",
     "iopub.status.idle": "2021-12-07T14:39:54.103111Z",
     "shell.execute_reply": "2021-12-07T14:39:54.102486Z",
     "shell.execute_reply.started": "2021-12-07T14:39:53.942997Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading in the dataframe with the urls\n",
    "site = pd.read_excel('Sonata_site_locations_v1.0.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e959e8b9-94de-42c9-a67b-cb64493c221d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:39:54.452606Z",
     "iopub.status.busy": "2021-12-07T14:39:54.452285Z",
     "iopub.status.idle": "2021-12-07T14:39:54.457251Z",
     "shell.execute_reply": "2021-12-07T14:39:54.456689Z",
     "shell.execute_reply.started": "2021-12-07T14:39:54.452583Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There were some issues with a couple of sites not being written on one line. This was solved by the following code\n",
    "site['Site'] = site['Site'].str.replace('\\n',' ') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec4de1-891f-4f7a-8d5e-689637fcaa62",
   "metadata": {},
   "source": [
    "#### Getting longitude and Lattitude from URL's\n",
    "To begin with, the longitude and lattitude was found for a single site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75beecf",
   "metadata": {},
   "source": [
    "### Using the functions to extract longitude and lattitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dc56df4-59e0-4454-888e-190a50dfc778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:39:57.023074Z",
     "iopub.status.busy": "2021-12-07T14:39:57.022602Z",
     "iopub.status.idle": "2021-12-07T14:39:57.040915Z",
     "shell.execute_reply": "2021-12-07T14:39:57.040155Z",
     "shell.execute_reply.started": "2021-12-07T14:39:57.023031Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "sitecoordinateslong = []\n",
    "sitecoordinateslat = []\n",
    "\n",
    "# Creating a list of the URLs from the site dataframe\n",
    "url_list = site['Pleiades URI'].tolist()\n",
    "\n",
    "# Making sure that it is a string\n",
    "url_list = map(str, url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d933f44",
   "metadata": {},
   "source": [
    "Here a for loop loops over all urls. If it is not an empty the above defined functions are used to find the longitude and lattitude. These are appended to the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "771e78ef-053b-4ced-a4cd-9810f9086cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:39:57.042715Z",
     "iopub.status.busy": "2021-12-07T14:39:57.042160Z",
     "iopub.status.idle": "2021-12-07T14:41:09.485152Z",
     "shell.execute_reply": "2021-12-07T14:41:09.482066Z",
     "shell.execute_reply.started": "2021-12-07T14:39:57.042683Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for url in url_list:\n",
    "    if url == 'nan':\n",
    "        long = ''\n",
    "        lat = ''\n",
    "\n",
    "    else:\n",
    "        long = longitude(url)\n",
    "        lat = lattitude(url)\n",
    "    \n",
    "    sitecoordinateslong.append(long)\n",
    "    sitecoordinateslat.append(lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f2ac8",
   "metadata": {},
   "source": [
    "Now the coordinates are appended to the site data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac3b9698-e589-4cda-b787-4fe1f623748c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:41:09.489617Z",
     "iopub.status.busy": "2021-12-07T14:41:09.489080Z",
     "iopub.status.idle": "2021-12-07T14:41:09.547991Z",
     "shell.execute_reply": "2021-12-07T14:41:09.547024Z",
     "shell.execute_reply.started": "2021-12-07T14:41:09.489567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, i in enumerate(sitecoordinateslat):\n",
    "    if i != '': # Ensuring that we do not overwrite the sites that did not have an url but includes coordinates in the first place\n",
    "        site.loc[index, 'Latitude'] = i\n",
    "\n",
    "for index, i in enumerate(sitecoordinateslong):\n",
    "    if i != '':\n",
    "        site.loc[index, 'Longitude'] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32687aa2",
   "metadata": {},
   "source": [
    "### Adding site information to original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "528577c4-0f4a-49e8-9f1b-c8a86b5cb072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:41:09.697929Z",
     "iopub.status.busy": "2021-12-07T14:41:09.697507Z",
     "iopub.status.idle": "2021-12-07T14:41:09.718211Z",
     "shell.execute_reply": "2021-12-07T14:41:09.717127Z",
     "shell.execute_reply.started": "2021-12-07T14:41:09.697888Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, site, how='inner', on = 'Site')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc820439",
   "metadata": {},
   "source": [
    "Checking to see if coordinates are included for all observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8280412-e5d7-4867-ad7f-a199da58ed9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:41:09.720307Z",
     "iopub.status.busy": "2021-12-07T14:41:09.719863Z",
     "iopub.status.idle": "2021-12-07T14:41:09.737991Z",
     "shell.execute_reply": "2021-12-07T14:41:09.736934Z",
     "shell.execute_reply.started": "2021-12-07T14:41:09.720259Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['Longitude'].isnull().values.any()\n",
    "df_merged['Latitude'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576c5f76",
   "metadata": {},
   "source": [
    "Saving the merged dataframe as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c35a3ec-5127-47fb-af0b-5b0bc17876f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T14:41:29.336808Z",
     "iopub.status.busy": "2021-12-07T14:41:29.336438Z",
     "iopub.status.idle": "2021-12-07T14:41:29.376964Z",
     "shell.execute_reply": "2021-12-07T14:41:29.375973Z",
     "shell.execute_reply.started": "2021-12-07T14:41:29.336781Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged.to_csv('data_including_site_information.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
